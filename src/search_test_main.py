"""
ê²€ìƒ‰ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì•±
"""

import sys
import time
from pathlib import Path

import pandas as pd
import streamlit as st

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.utils.search_engine import DinerSearchEngine

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="  ê²€ìƒ‰ ì—”ì§„ í…ŒìŠ¤íŠ¸", page_icon="ğŸ½ï¸", layout="wide")

# ì œëª©
st.title("ğŸ½ï¸   ê²€ìƒ‰ ì—”ì§„ í…ŒìŠ¤íŠ¸")
st.markdown("---")


def handle_feedback(score, text, row):
    """í”¼ë“œë°±ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    st.success(f"âœ… í‰ê°€ ì™„ë£Œ! {row['name']}ì— {score}ì ì„ ì£¼ì…¨ìŠµë‹ˆë‹¤.")
    if text:
        st.info(f"ğŸ’¬ ì˜ê²¬: {text}")

    # í”¼ë“œë°± ë°ì´í„°ë¥¼ session_stateì— ì €ì¥
    if "feedback_data" not in st.session_state:
        st.session_state.feedback_data = []

    st.session_state.feedback_data.append(
        {
            "diner_idx": row["idx"],
            "diner_name": row["name"],
            "score": score,
            "comment": text,
            "match_type": row["match_type"],
            "timestamp": time.time(),
        }
    )


@st.cache_data
def load_diner_data():
    """ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # ê°€ì¥ ìµœì‹  ë°ì´í„° íŒŒì¼ ì‚¬ìš©
        data_file = "data/whatToEat_DB_seoul_diner_20250301.csv"
        df = pd.read_csv(data_file)

        # ê¸°ë³¸ ì •ë³´ë§Œ ì¶”ì¶œ (diner_idx, diner_name)
        if "diner_idx" in df.columns and "diner_name" in df.columns:
            basic_df = df[["diner_idx", "diner_name"]].dropna()
            st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(basic_df)}ê°œ  ")
            return basic_df
        else:
            st.error("âŒ ë°ì´í„° íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼(diner_idx, diner_name)ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None


def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ”§ ê²€ìƒ‰ ì„¤ì •")

    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
        df_basic = load_diner_data()

    if df_basic is None:
        st.stop()

    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    search_engine = DinerSearchEngine()
    search_engine.load_basic_data(df_basic)

    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
    st.sidebar.subheader("ê²€ìƒ‰ íŒŒë¼ë¯¸í„°")
    top_k = st.sidebar.slider("ìƒìœ„ ê²°ê³¼ ìˆ˜", min_value=1, max_value=20, value=5)
    jamo_threshold = st.sidebar.slider(
        "ìëª¨ ì„ê³„ê°’", min_value=0.5, max_value=1.0, value=0.9, step=0.05
    )
    jamo_candidate_threshold = st.sidebar.slider(
        "ìëª¨ í›„ë³´ ì„ê³„ê°’", min_value=0.3, max_value=0.9, value=0.7, step=0.05
    )

    # ê²€ìƒ‰ ì˜ì—­
    st.header("ğŸ”   ê²€ìƒ‰")

    # ê²€ìƒ‰ ì…ë ¥ê³¼ ê²°ê³¼ë¥¼ popoverë¡œ ë¶„ë¦¬
    with st.popover("ğŸ” ê²€ìƒ‰í•˜ê¸°", help="í´ë¦­í•˜ì—¬ ê²€ìƒ‰ì°½ì„ ì—´ì–´ë³´ì„¸ìš”"):
        st.subheader("  ê²€ìƒ‰")

        # ê²€ìƒ‰ ì…ë ¥
        col1, col2 = st.columns([3, 1])
        with col1:
            # ìƒ˜í”Œ ê²€ìƒ‰ì–´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            default_query = st.session_state.get("sample_query", "")
            query = st.text_input(
                "  ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”",
                value=default_query,
                placeholder="ì˜ˆ: ë§›ìˆëŠ”ì§‘, ìŠ¤ì‹œë¡œ, í”¼ìí—›...",
                help="ì •í™•í•œ ë§¤ì¹­, ë¶€ë¶„ ë§¤ì¹­, ìëª¨ ë§¤ì¹­ì„ ì§€ì›í•©ë‹ˆë‹¤.",
            )
            # ìƒ˜í”Œ ê²€ìƒ‰ì–´ ì‚¬ìš© í›„ ì´ˆê¸°í™”
            if "sample_query" in st.session_state:
                del st.session_state.sample_query

        with col2:
            search_button = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

        # ê²€ìƒ‰ ì‹¤í–‰
        if search_button and query.strip():
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            st.session_state.search_query = query.strip()
            st.session_state.search_results = None
            st.session_state.searching = True
            st.rerun()

    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ë©”ì¸ í™”ë©´)
    if hasattr(st.session_state, "searching") and st.session_state.searching:
        st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼")

        # ê²€ìƒ‰ ì‹¤í–‰
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            try:
                results = search_engine.search(
                    query=st.session_state.search_query,
                    top_k=top_k,
                    jamo_threshold=jamo_threshold,
                    jamo_candidate_threshold=jamo_candidate_threshold,
                )

                # ê²€ìƒ‰ ì™„ë£Œ ìƒíƒœë¡œ ë³€ê²½
                st.session_state.search_results = results
                st.session_state.searching = False

            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.session_state.searching = False

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if (
        hasattr(st.session_state, "search_results")
        and st.session_state.search_results is not None
    ):
        results = st.session_state.search_results

        if not results.empty and "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" not in results["match_type"].values:
            st.success(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! {len(results)}ê°œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

            # st.write_streamì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
            def generate_results():
                yield f"**ê²€ìƒ‰ì–´**: {st.session_state.search_query}\n\n"
                yield f"**ì´ {len(results)}ê°œ ê²°ê³¼**\n\n"

                for i, (_, row) in enumerate(results.iterrows(), 1):
                    yield f"### {i}. {row['name']}\n"
                    yield f"- **  ID**: {row['idx']}\n"
                    yield f"- **ë§¤ì¹­ íƒ€ì…**: {row['match_type']}\n"
                    if "jamo_score" in row and pd.notna(row["jamo_score"]):
                        yield f"- **ìëª¨ ì ìˆ˜**: {row['jamo_score']:.2f}\n"
                    yield "\n"
                    time.sleep(0.1)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼

                yield "---\n"
                yield "**ê²€ìƒ‰ í†µê³„**\n"
                match_counts = results["match_type"].value_counts()
                for match_type, count in match_counts.items():
                    yield f"- {match_type}: {count}ê°œ\n"

            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
            st.write_stream(generate_results)

            # ê° ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°± ë²„íŠ¼
            st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ í‰ê°€")
            st.info("ê°  ì— ëŒ€í•´ 1~5ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”!")

            for i, (_, row) in enumerate(results.iterrows(), 1):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**{i}. {row['name']}** ({row['match_type']})")
                with col2:
                    feedback = st.feedback(
                        options="stars",
                        key=f"feedback_{row['idx']}_{i}",
                        # on_submit=lambda score, text: handle_feedback(score, text, row),
                    )
                    st.write(f"feedback: {feedback}")

        else:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")

    # ìƒ˜í”Œ ê²€ìƒ‰ì–´ ì œì•ˆ
    st.markdown("---")
    st.subheader("ğŸ’¡ ìƒ˜í”Œ ê²€ìƒ‰ì–´")

    sample_queries = [
        "ë§›ìˆëŠ”ì§‘",
        "ìŠ¤ì‹œë¡œ",
        "í”¼ìí—›",
        "ë§¥ë„ë‚ ë“œ",
        "ë²„ê±°í‚¹",
        "ìŠ¤íƒ€ë²…ìŠ¤",
        "íˆ¬ì¸í”Œë ˆì´ìŠ¤",
        "ì´ë””ì•¼",
        "í• ë¦¬ìŠ¤",
        "íŒŒë¦¬ë°”ê²ŒíŠ¸",
    ]

    cols = st.columns(5)
    for i, query_sample in enumerate(sample_queries):
        with cols[i % 5]:
            if st.button(query_sample, key=f"sample_{i}"):
                st.session_state.sample_query = query_sample
                st.rerun()

    # í”¼ë“œë°± ë°ì´í„° í‘œì‹œ
    if hasattr(st.session_state, "feedback_data") and st.session_state.feedback_data:
        st.markdown("---")
        st.subheader("ğŸ“ í‰ê°€ ê¸°ë¡")

        feedback_df = pd.DataFrame(st.session_state.feedback_data)
        if not feedback_df.empty:
            # ìµœê·¼ í‰ê°€ë¶€í„° í‘œì‹œ
            feedback_df = feedback_df.sort_values("timestamp", ascending=False)

            for _, row in feedback_df.iterrows():
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    st.write(f"**{row['diner_name']}** ({row['match_type']})")
                with col2:
                    st.write(f"ì ìˆ˜: {'â­' * int(row['score'])}")
                with col3:
                    if row["comment"]:
                        st.write(f"ğŸ’¬ {row['comment']}")

            # í‰ê°€ í†µê³„
            st.subheader("ğŸ“Š í‰ê°€ í†µê³„")
            col1, col2, col3 = st.columns(3)
            with col1:
                avg_score = feedback_df["score"].mean()
                st.metric("í‰ê·  ì ìˆ˜", f"{avg_score:.1f}ì ")
            with col2:
                total_feedback = len(feedback_df)
                st.metric("ì´ í‰ê°€ ìˆ˜", f"{total_feedback}ê°œ")
            with col3:
                match_type_counts = feedback_df["match_type"].value_counts()
                most_common = (
                    match_type_counts.index[0]
                    if not match_type_counts.empty
                    else "ì—†ìŒ"
                )
                st.metric("ê°€ì¥ ë§ì€ ë§¤ì¹­ íƒ€ì…", most_common)

    # í†µê³„ ì •ë³´
    st.markdown("---")
    st.subheader("ğŸ“ˆ ë°ì´í„° í†µê³„")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´   ìˆ˜", f"{len(df_basic):,}ê°œ")

    with col2:
        #  ëª… ê¸¸ì´ í†µê³„
        name_lengths = df_basic["diner_name"].str.len()
        avg_length = name_lengths.mean()
        st.metric("í‰ê·   ëª… ê¸¸ì´", f"{avg_length:.1f}ì")

    with col3:
        # í•œê¸€   ìˆ˜
        korean_names = df_basic["diner_name"].str.contains(r"[ê°€-í£]", na=False)
        korean_count = korean_names.sum()
        st.metric("í•œê¸€   ìˆ˜", f"{korean_count:,}ê°œ")


if __name__ == "__main__":
    main()
